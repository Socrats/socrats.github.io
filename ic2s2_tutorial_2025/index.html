<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html lang="eng">
<head>
    <title>IC2S2 Tutorial on RL and EGT</title>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no"/>
    <link rel="stylesheet" href="assets/css/main.css"/>
    <noscript>
        <link rel="stylesheet" href="assets/css/noscript.css"/>
    </noscript>

    <link rel="icon" href="https://efernandez.eu/images/avatar.png">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@nytimes">
    <meta name="twitter:creator" content="@esocrats">
    <meta name="twitter:title" content="EGT Tutorial at ECAI23">
    <meta name="twitter:description"
          content="Social Dynamics and Evolutionary Game Theory Tutorial at ECAI 2023. Dates: to be determined.">
    <meta name="twitter:image"
          content="https://efernandez.eu/images/avatar.png">
</head>
<body class="is-preload">

<!-- Wrapper -->
<div id="wrapper">

    <!-- Header -->
    <header id="header" class="alt">
        <span class="logo"><img src="images/logo.svg" alt=""/></span>
        <h1>Reinforcement Learning and Evolutionary Game Theory Are Two Sides of the Same Coin</h1>
        <p>
            Evolutionary Game Theory (EGT) and Multi-Agent Reinforcement Learning (MARL) provide powerful methodological
            frameworks for the study of the evolution of cooperation in large populations. The main objective of this
            tutorial is to help social science practitioners acquire these new tools coming form AI and complex systems,
            and computer science practitioners to understand their research in terms of economic models. With this, we
            believe the present tutorial will raise awareness of the importance of EGT and RL for the study and
            modelling of social dynamics in large populations, and introduce methods of wide relevance for the <a
                href="https://www.ic2s2-2025.org">IC<sup>2</sup>S<sup>2</sup></a>
            community.
        </p>
    </header>

    <!-- Nav -->
    <nav id="nav">
        <ul>
            <li><a href="#intro" class="active">Summary</a></li>
            <li><a href="#speaker">Speakers</a></li>
            <li><a href="#first">Format and Outline</a></li>
            <li><a href="#second">Pre-requisites</a></li>
            <li><a href="#cta">Material</a></li>
            <li><a href="#references">References</a></li>
        </ul>
    </nav>

    <!-- Main -->
    <div id="main">

        <!-- Introduction -->
        <section id="intro" class="main">
            <div class="spotlight">
                <div class="content">
                    <header class="major">
                        <h2>Summary</h2>
                        <h3>Presenters: Elias Fernández Domingos and Paolo Turrini</h3>
                    </header>
                    <p>Classical equilibrium analysis makes overly simplistic assumptions about players' cognitive
                        capacity, such as common knowledge of the game structure and common knowledge of rationality.
                        Assuming that individuals are rational is often unjustified in many social and biological
                        systems, even for simple pairwise interactions. Moreover, whenever the problem requires a proper
                        understanding of conflicts occurring in large populations, it becomes necessary to characterise
                        the choices and strategies of many individuals throughout time, and not only at equilibrium. As
                        such, in many real-world multi-agent systems, the goal is shifted towards the understanding of
                        the complex ecologies of behaviours emerging from a given dilemma (or "game"). This is where
                        evolutionary game theory (EGT) shines as a theoretical and computational framework. Likewise,
                        from the computational perspective, multi-agent reinforcement learning (MARL) models how
                        self-interested agents learn and improve their policies through the accumulation of rewards
                        coming from their past experience. Just like strategies in evolutionary game theory adapting to
                        one another, agents' actions evolve based on their empirical returns. The similarity is no
                        coincidence. In this tutorial we show how these two frameworks, although applied in different
                        context, are two sides of the same coin, presenting fundamental mathematical results that
                        demonstrate how the equilibria of population dynamics can be encoded by simple RL agents
                        policies and the other way round.
                    </p>
                    <p>
                        We will provide use-cases in which each modelling framework is useful. This tutorial will help
                        the social science practitioner acquire new tools coming from AI and complex systems, and
                        computer science practitioners to understand their research in terms of economic models.
                        Students will be able to follow the tutorial interactively through a series of Jupyter Notebooks
                        that will be provided. Our objective is to offer a hands-on experience on how to use EGT and
                        MARL to model social dynamics.
                    </p>
                </div>
            </div>
        </section>

        <section id="speaker" class="main">
            <header class="major">
                <h2>Speakers</h2>
            </header>
            <div class="card-deck">
                <div class="card">
                    <div class="container" style="flex-basis:83%">
                        <h2><b>Elias Fernández Domingos</b></h2>
                        <h3>Postdoctoral Researcher at the AI Lab, Vrije Universiteit Brussel,
                            Belgium</h3>
                        <p>Elias is currently a Post-doctoral researcher (F.W.O. fellow) at the Artificial Intelligence
                            Lab
                            of the Vrije
                            Universiteit Brussel. Also affiliated with the Machine Learning Group (Université Libre de
                            Bruxelles). He is interested in the origins of cooperation in social interactions and how we
                            can
                            maintain it in an increasingly complex and hybrid human-AI world. In his research, he
                            applies
                            concepts and methods from (Evolutionary) Game Theory, Behavioural economics, and Machine
                            Learning to model collective (strategic) behaviour and validate it through behavioural
                            economic
                            Experiments. He is the creator of <a href="https://github.com/Socrats/EGTTools">EGTtools</a>
                            a
                            Python/C++
                            toolbox for Evolutionary Game Theory.
                        </p>
                    </div>
                    <img style="flex-basis:17%" src="images/profile_e_web.png" alt="personal picture"/>
                </div>
                <br>
                <div class="card">
                    <div class="container" style="flex-basis:83%">
                        <h2><b>Paolo Turrini</b></h2>
                        <h3>Associate Professor. Department of Computer Science, University of Warwick, UK</h3>
                        <p> Paolo is interested in AI for social good, uses game theory and RL to design agents that
                            achieve
                            socially desirable objectives. Consistently publishes in top AI venues. PhD from Utrecht
                            University, COFUND Marie Curie Fellow at the University of Luxembourg and Intra-European
                            Marie Curie Fellow at Imperial College London, Imperial College Research Fellow.
                            Now member of Board of Directors at IFAAMAS, the International Foundation for Autonomous
                            Agents Research.
                        </p>
                    </div>
                    <img style="flex-basis:17%" src="images/profile_p_web.png" alt="personal picture"/>
                </div>
            </div>
        </section>

        <!-- First Section -->
        <section id="first" class="main">
            <div class="spotlight">
                <div class="content">
                    <header class="major">
                        <h2>Format and Outline</h2>
                    </header>
                    <p>
                        We divide the tutorial into two sections of 85 minutes with a 10 minutes rest in between (a
                        total of 3h):
                    </p>
                    <ol>
                        <li>
                            Part 1: Introduction to Evolutionary Game Theory
                            <ol>
                                <li>Introduction and Motivation/li>
                                <li>Infinite populations</li>
                                <li>Finite populations</li>
                                <li>Games on networks</li>
                            </ol>
                        </li>
                        <li>
                            Part 2: Introduction to Multi-Agent Reinforcement Learning
                            <ol>
                                <li>Many learning agents</li>
                                <li>Key algorithms (Cross-Learning, Q-learning)
                                </li>
                                <li>Connection with EGT</li>
                                <li>Emergence of Norms among learning agents</li>
                            </ol>
                        </li>
                    </ol>
                    <p>
                        Each part of the tutorial will be accompanied by a Jupyter notebook which will contain the
                        examples shown in the presentation. In this way, participants will be able to follow
                        interactively the presentation, and test themselves the outcome of the framework in different
                        scenarios.
                    </p>
                </div>
            </div>
        </section>

        <!-- Second Section -->
        <section id="second" class="main">
            <div class="spotlight">
                <div class="content">
                    <header class="major">
                        <h2>Pre-requisites</h2>
                    </header>
                    <p>Even though this tutorial aims to target a general audience in AI, we recommend to have
                        basic knowledge in the following areas:</p>
                    <ul>
                        <li>Basic knowledge of Dynamical Systems</li>
                        <li>Basic knowledge of Reinforcement Learning</li>
                        <li>Basic knowledge of Markov Chains</li>
                        <li>Basic knowledge of Game Theory</li>
                    </ul>
                </div>
            </div>
        </section>

        <!-- Get Started -->
        <section id="cta" class="main special">
            <header class="major">
                <h2>Material</h2>
            </header>
            <p>We have prepared some jupyter notebooks for you to follow the tutorial interactively. You can access them
                here and can run them in Google Colab: <a href="https://github.com/Socrats/ic2s2-tutorial">Tutorial
                    Notebooks</a></p>
        </section>

        <!-- Get Started -->
        <section id="references" class="main">
            <header class="major">
                <h2>Important References</h2>
            </header>
            <ol>
                <li>Nash Jr, John F. "Equilibrium points in n-person games." Proceedings of the national academy of
                    sciences 36.1 (1950): 48-49.
                </li>
                <li>M. Nowak, Evolutionary dynamics; exploring the equations of life.</li>
                <li>Sigmund, K., 2010. The Calculus of Selfishness. Princeton University Press.</li>
                <li>Boccaletti, S., Latora, V., Moreno, Y., Chavez, M. & Hwang, D. Complex networks: Structure and
                    dynamics. Physics Reports 424, 175–308 (2006).
                </li>
                <li>Domingos, Elias Fernández, Francisco C. Santos, and Tom Lenaerts. "EGTtools: Evolutionary game
                    dynamics in Python." Iscience 26.4 (2023).
                </li>
            </ol>
        </section>

    </div>

    <!-- Footer -->
    <footer id="footer">
        <section>
            <h2>Elias Fernández Domingos</h2>
            <p>I am a post-doctoral researcher working in the intersection of AI, Behavioral Economics and Complex
                Systems. I am currently affiliated with the Université Libre de Bruxelles (ULB) and the Vrije
                Universiteit Brussel (VUB), both in Belgium.</p>
            <ul class="actions">
                <li><a href="generic.html" class="button">Learn More</a></li>
            </ul>
        </section>
        <section>
            <h2>Contact</h2>
            <dl class="alt">
                <dt>Email</dt>
                <dd>elias dot fernandez dot domingos at vub dot be</dd>
            </dl>
            <ul class="icons">
                <li><a href="https://twitter.com/esocrats" class="icon brands fa-twitter alt"><span
                        class="label">Twitter</span></a></li>
                <li><a href="https://github.com/Socrats" class="icon brands fa-github alt"><span
                        class="label">GitHub</span></a></li>
            </ul>
        </section>
        <p class="copyright">&copy; Elias Fernández Domingos. | Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
    </footer>

</div>

<!-- Scripts -->
<script src="assets/js/jquery.min.js"></script>
<script src="assets/js/jquery.scrollex.min.js"></script>
<script src="assets/js/jquery.scrolly.min.js"></script>
<script src="assets/js/browser.min.js"></script>
<script src="assets/js/breakpoints.min.js"></script>
<script src="assets/js/util.js"></script>
<script src="assets/js/main.js"></script>

</body>
</html>